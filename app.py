import streamlit as st
import pandas as pd
import io
import hashlib  # æ–°å¢žï¼šç”¨äºŽè®¡ç®— MD5

# ==========================================
# é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="Zumaè¡¨æ ¼å·¥å…·", layout="wide")
st.title("ðŸ“Š Zumaè¡¨æ ¼æ•°æ®ç­›é€‰ä¸Žåˆå¹¶å·¥å…· (ç»Ÿè®¡å¢žå¼º + IDç”Ÿæˆç‰ˆ)")

# ==========================================
# 1. ä¾§è¾¹æ ï¼šè®¾ç½®ç­›é€‰æ¡ä»¶
# ==========================================
st.sidebar.header("1. è®¾ç½®ç­›é€‰æ¡ä»¶")

# Times ç­›é€‰
st.sidebar.subheader("Times (å€æ•°) èŒƒå›´")
st.sidebar.info("è®¡ç®—å…¬å¼: Times = (Amount + 10000) / 10000")
min_times = st.sidebar.number_input("Times æœ€å°å€¼", value=0.0, step=0.1, format="%.2f")
max_times = st.sidebar.number_input("Times æœ€å¤§å€¼", value=1000.0, step=0.1, format="%.2f")

# LauncherNum ç­›é€‰
st.sidebar.subheader("LauncherNum (å‘å°„æ•°) èŒƒå›´")
min_launcher = st.sidebar.number_input("LauncherNum æœ€å°å€¼", value=0)
max_launcher = st.sidebar.number_input("LauncherNum æœ€å¤§å€¼", value=100)

# ==========================================
# 2. å…¨èƒ½è¯»å–å‡½æ•°
# ==========================================
def super_reader(file):
    """å°è¯•å¤šç§æ–¹å¼è¯»å– Excel æˆ– CSV"""
    # ç­–ç•¥ 1: Excel
    try:
        all_sheets = pd.read_excel(file, sheet_name=None)
        best_df = pd.DataFrame()
        max_rows = 0
        for name, sheet_df in all_sheets.items():
            if len(sheet_df) > max_rows:
                max_rows = len(sheet_df)
                best_df = sheet_df
        if not best_df.empty:
            return best_df
    except:
        pass
    
    # ç­–ç•¥ 2: CSV (å°è¯•ä¸åŒç¼–ç å’Œå®¹é”™)
    methods = [
        (pd.read_csv, {}),
        (pd.read_csv, {'encoding': 'gbk'}),
        (pd.read_csv, {'on_bad_lines': 'skip'}),
    ]
    
    for reader, kwargs in methods:
        file.seek(0)
        try:
            df = reader(file, **kwargs)
            if not df.empty: return df
        except:
            continue
            
    return None

# ==========================================
# 3. ä¸»ç•Œé¢é€»è¾‘
# ==========================================
st.header("2. ä¸Šä¼ æ•°æ®æ–‡ä»¶")
uploaded_files = st.file_uploader(
    "è¯·ä¸Šä¼  Excel æˆ– CSV æ–‡ä»¶ (æ”¯æŒå¤šæ–‡ä»¶)", 
    type=['xlsx', 'xls', 'csv'],
    accept_multiple_files=True
)

if uploaded_files:
    all_data_frames = []
    
    # æ˜¾ç¤ºå¤„ç†è¿›åº¦
    with st.spinner(f"æ­£åœ¨è¯»å–å¹¶é¢„å¤„ç† {len(uploaded_files)} ä¸ªæ–‡ä»¶..."):
        for file in uploaded_files:
            # è¯»å–
            df = super_reader(file)
            
            if df is not None and not df.empty:
                try:
                    # æ¸…æ´—åˆ—å
                    df.columns = df.columns.astype(str).str.strip()
                    
                    # æ£€æŸ¥å¿…è¦åˆ—
                    if 'Amount' in df.columns and 'LauncherNum' in df.columns:
                        # è®¡ç®— Times
                        df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce').fillna(0)
                        df['Times'] = (df['Amount'] + 10000) / 10000
                        all_data_frames.append(df)
                except Exception as e:
                    st.error(f"å¤„ç†æ–‡ä»¶ {file.name} æ—¶å‡ºé”™: {e}")

    if all_data_frames:
        # åˆå¹¶æ‰€æœ‰æ•°æ®ç”¨äºŽç»Ÿè®¡
        master_df = pd.concat(all_data_frames, ignore_index=True)
        
        # ==========================================
        # ç»Ÿè®¡ä¿¡æ¯æ¨¡å— (Statistics)
        # ==========================================
        st.markdown("### ðŸ“ˆ æ•°æ®å…¨è²Œç»Ÿè®¡")
        st.info("è¿™é‡Œå±•ç¤ºçš„æ˜¯**æ‰€æœ‰ä¸Šä¼ æ–‡ä»¶**åˆå¹¶åŽçš„åŽŸå§‹æ•°æ®ç»Ÿè®¡ï¼Œä¾›æ‚¨å‚è€ƒä»¥è®¾ç½®ç­›é€‰æ¡ä»¶ã€‚")
        
        stat_col1, stat_col2, stat_col3 = st.columns(3)
        stat_col1.metric("ðŸ“¦ æ€»æ•°æ®è¡Œæ•°", f"{len(master_df):,} è¡Œ")
        
        t_min_val = master_df['Times'].min()
        t_max_val = master_df['Times'].max()
        stat_col2.metric("âœ–ï¸ Times (å€æ•°) èŒƒå›´", f"{t_min_val:.2f} ~ {t_max_val:.2f}")
        
        l_min_val = master_df['LauncherNum'].min()
        l_max_val = master_df['LauncherNum'].max()
        stat_col3.metric("ðŸš€ LauncherNum (å‘å°„) èŒƒå›´", f"{l_min_val} ~ {l_max_val}")
        
        st.divider()

        # ==========================================
        # ç­›é€‰ä¸Žå¯¼å‡ºæ¨¡å—
        # ==========================================
        st.markdown("### ðŸ” æ•°æ®ç­›é€‰ä¸Žç”Ÿæˆ")
        
        if st.button("ðŸ‘‰ æŒ‰å·¦ä¾§æ¡ä»¶å¼€å§‹ç­›é€‰å¹¶å¯¼å‡º", type="primary"):
            
            # 1. æ‰§è¡Œç­›é€‰
            filtered_df = master_df[
                (master_df['Times'] >= min_times) & 
                (master_df['Times'] <= max_times) & 
                (master_df['LauncherNum'] >= min_launcher) & 
                (master_df['LauncherNum'] <= max_launcher)
            ].copy() # copyå¾ˆé‡è¦ï¼Œé¿å…SettingWithCopyWarning
            
            if not filtered_df.empty:
                # 2. è°ƒæ•´åˆ—é¡ºåº (Times æ”¾åœ¨ Amount åŽé¢)
                cols = list(filtered_df.columns)
                if 'Times' in cols and 'Amount' in cols:
                    cols.remove('Times')
                    amount_idx = cols.index('Amount')
                    cols.insert(amount_idx + 1, 'Times')
                    filtered_df = filtered_df[cols]

                # ==========================================
                # ã€æ–°å¢žåŠŸèƒ½ã€‘ MD5 å’Œ ID ç”Ÿæˆ
                # ==========================================
                with st.spinner('æ­£åœ¨ç”Ÿæˆ MD5 å’Œ Batch ID...'):
                    # A. ç”Ÿæˆ MD5 (å¯¹å…¨è¡Œå†…å®¹)
                    def calculate_md5(row):
                        row_str = "".join(row.astype(str).values)
                        return hashlib.md5(row_str.encode('utf-8')).hexdigest()
                    
                    md5_series = filtered_df.apply(calculate_md5, axis=1)

                    # B. ç”Ÿæˆ Batch_ID (å¹³å‡å€¼æ³•)
                    # é€»è¾‘ï¼š((Min + Max) / 2) * 100 æ ¼å¼åŒ–ä¸º6ä½ + è¡Œå·6ä½
                    avg_val = (min_times + max_times) / 2
                    prefix_int = int(round(avg_val * 100))
                    prefix_str = str(prefix_int).zfill(6)
                    
                    # ç”Ÿæˆ ID åˆ—è¡¨
                    ids = []
                    WIDTH_INDEX = 6
                    # é‡ç½® index ä»¥ä¾¿äºŽç”Ÿæˆè¿žç»­æµæ°´å·ï¼Œä½†ä¸æ”¹å˜åŽŸå§‹æ•°æ®é¡ºåº
                    for i in range(len(filtered_df)):
                        idx_str = str(i + 1).zfill(WIDTH_INDEX)
                        full_id = f"{prefix_str}{idx_str}"
                        ids.append(full_id)

                    # æ’å…¥æ–°åˆ—åˆ°æœ€å‰é¢
                    filtered_df.insert(0, 'Batch_ID', ids)
                    filtered_df